defaults:
  - experiment_config
  - _self_

sampling_device: "cpu"
train_device: "cpu"

share_policy_params: True
prefer_continuous_actions: True

gamma: 0.99
lr: 0.00005
clip_grad_norm: True
clip_grad_val: 5

soft_target_update: True
polyak_tau: 0.005
hard_target_update_frequency: 5

exploration_eps_init: 0.8
exploration_eps_end: 0.01

collected_frames_per_batch: 6000
n_envs_per_worker: 10
n_iters: 500
n_optimizer_steps: 45

on_policy_minibatch_size: 400

off_policy_memory_size: 1_000_000
off_policy_train_batch_size: 15_000

evaluation: True
evaluation_interval: 20
evaluation_episodes: 10

loggers: [wandb]
create_json: True

restore_file: null
checkpoint_interval: 50
